{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search Script Scrape by Dan Nguyen for Stanford Computational Journalism**\n",
    "\n",
    "Learn how to scrape by writing 101 scrapers. All scrapers below are written by me, Winny de Jong. Some scrapers are written multiple times using different libraries/techniques. Just because. \n",
    "\n",
    "- [The original Github Repository](https://github.com/stanfordjournalism/search-script-scrape)\n",
    "- Article by Dan Nguyen [with background info](http://blog.danwin.com/examples-of-web-scraping-in-python-3-x-for-data-journalists/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [504]>\n"
     ]
    }
   ],
   "source": [
    "# Scraper 101\n",
    "# Goal: get number of women currently serving in the U.S. Congress, according to Sunlight Foundation data \n",
    "\n",
    "import requests\n",
    "\n",
    "# set vars\n",
    "url = \"https://congress.api.sunlightfoundation.com/legislators&gender=F\"\n",
    "filters = \"&genders=f\"\n",
    "# do request\n",
    "r = requests.get(url)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Scraper 004 - \n",
    "# Goal: get the number of librarian-related job positions that the federal government is currently hiring for \n",
    "\n",
    "# import needed libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# collect basic info in vars\n",
    "code = 1410\n",
    "url = \"https://www.usajobs.gov/Search/?k=\"\n",
    "\n",
    "\"\"\"\n",
    "<h4 id=\"page-info\" class=\"usajobs-search-controls__results-count\">\n",
    "            Viewing 1 â€“ 10 of 11 jobs\n",
    "        </h4>\n",
    "\"\"\"\n",
    "\n",
    "# do request\n",
    "r = requests.get(url+str(code))\n",
    "# get text, save to html\n",
    "html = r.text\n",
    "# create soup using html\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "# find h4 with class usajobs-search-controls__results-count\n",
    "positions = soup.find('h4', {'class': 'usajobs-search-controls__results-count'})\n",
    "# print number of librarian-related job positions\n",
    "print(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
